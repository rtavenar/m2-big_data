{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9znJKoILnuz"
      },
      "source": [
        "# Prise en main de PySpark\n",
        "\n",
        "## Installation et configuration\n",
        "\n",
        "**Question 1 : pré-requis**\n",
        "\n",
        "Téléchargez le fichier `cereal.csv` sur CURSUS et ajoutez-le dans un nouveau dossier `/user/VOTRE_PRENOM/tp_pyspark` sur le HDFS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zveiA1IRMKDK"
      },
      "source": [
        "**Question 2**\n",
        "\n",
        "Exécutez la cellule ci-dessous pour connaître le nombre de coeurs de calcul qui vous sont attribués sur la machine actuelle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpffJPYDNOu-",
        "outputId": "65274043-5c2e-4ba7-f18e-d2d5232e7b03"
      },
      "outputs": [],
      "source": [
        "from os import cpu_count\n",
        "# get the number of logical cpu cores\n",
        "n_cores = cpu_count()\n",
        "# report the number of logical cpu cores\n",
        "print(f'Number of Logical CPU cores: {n_cores}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkSaS7doNVPT"
      },
      "source": [
        "**Question 3**\n",
        "\n",
        "Ci-dessous, créer une `SparkSession` pour une application nommée \"Test de PySpark\" et lancée en local avec le nombre de coeurs trouvé ci-dessus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Rs5n3gR1QM0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJWc4fGbORcm"
      },
      "source": [
        "## Quelques tests sur les RDDs\n",
        "\n",
        "### Transformations, actions et persistence\n",
        "\n",
        "**Question 4**\n",
        "\n",
        "Ci-dessous, créer deux RDDs (nommés `my_rdd1` et `my_rdd2`) à partir de deux listes Python de 6 éléments chacune.\n",
        "\n",
        "Afficher ces `RDD` avec `print()` ainsi que leur nombre de partitions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TK6q1cLA2iFP",
        "outputId": "a2f6be00-94fe-4702-e20a-4b6744b5247a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARUky-JtOiJW"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from operator import add\n",
        "\n",
        "def carre_slow(x):\n",
        "  time.sleep(1)\n",
        "  return x**2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZg706wUPE-O"
      },
      "source": [
        "**Question 5**\n",
        "\n",
        "Executer la cellule de code ci-dessus, puis utiliser la méthode `map` des RDDs pour générer un nouveau RDD nommé `my_new_rdd1` contenant les carrés des valeurs de `my_rdd1`, en utilisant la fonction `carre_slow` définie ci-dessus.\n",
        "\n",
        "Mesurer le temps d'exécution (`%%time`) et conclure : les traitements ont-ils réellement été exécutés à cet endroit ?\n",
        "\n",
        "Afficher le nouveau RDD généré et son nombre de partitions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qoZARjj3sye",
        "outputId": "84e70ee6-a094-4ace-c07c-c8a3b0ef0e8b"
      },
      "outputs": [],
      "source": [
        "%%time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wepCWsf1X6c1"
      },
      "source": [
        "**Question 6**\n",
        "\n",
        "En mesurant le temps d'exécution, utiliser la méthode `collect` pour récupérer et afficher le contenu du RDD `my_new_rdd1` dans le *driver program* (programme principal, ici celui du Notebook).\n",
        "\n",
        "Conclure quant aux traitements lancés au moment de l'appel à `collect` et à la nature de cette méthode : est-ce une transformation ou une action ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKbV1ueg5lxb",
        "outputId": "fab10107-9632-4874-be46-731b88c54ef1"
      },
      "outputs": [],
      "source": [
        "%%time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNz-N_3wY_qN"
      },
      "source": [
        "**Question 7**\n",
        "\n",
        "En mesurant les temps d'exécution, calculer à l'aide de la méthode `reduce` la somme des carrés contenus dans `my_new_rdd1` (on pourra utiliser la fonction `add` du module `operator` importée ci-dessus).\n",
        "\n",
        "Qu'observez-vous au niveau du temps d'exécution ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0CxZjeu50CX",
        "outputId": "69c6c571-4707-4b9b-86dd-5b2c139421f1"
      },
      "outputs": [],
      "source": [
        "%%time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7dR2GsRkPaY"
      },
      "source": [
        "**Question 8**\n",
        "\n",
        "De la même manière, générer un nouveau RDD nommé `my_new_rdd2` contenant les carrés des valeurs de `my_rdd2`, en utilisant la fonction `carre_slow` puis appeler la méthode `persist` sur ce nouveau RDD.\n",
        "\n",
        "Dans la seconde cellule, en mesurant le temps d'exécution, afficher le contenu de `my_new_rdd2` en utilisant la méthode `collect`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cldsy-Al8Klb",
        "outputId": "5ef22564-7b6d-414c-b2af-9e9d206a61c4"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUJXXoMQlI1X",
        "outputId": "66c4d944-71c0-4a14-e61f-fd26020f69f2"
      },
      "outputs": [],
      "source": [
        "%%time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_5olg3Ym1zD"
      },
      "source": [
        "**Question 9**\n",
        "\n",
        "En mesurant les temps d'exécution, calculer à l'aide de la méthode `reduce`la somme des carrés contenus dans `my_new_rdd2`.\n",
        "\n",
        "Qu'observez-vous cette fois-ci au niveau du temps d'exécution ?\n",
        "\n",
        "Conclure : à votre avis, à quoi sert la méthode `persist` appelée ci-dessus sur `my_new_rdd2` ? Vérifier en consultant la [documentation en ligne](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.persist.html#pyspark.RDD.persist)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilvG6AtV8Sya",
        "outputId": "7d281ccd-7751-4f4a-aa86-966da359578c"
      },
      "outputs": [],
      "source": [
        "%%time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7lEzeDAplJm"
      },
      "source": [
        "## Utilisation de Spark SQL\n",
        "\n",
        "### Lecture et mise en forme des données\n",
        "\n",
        "*Remarque : lors des différentes transformations de votre DataFrame il est conseillé d'afficher le résultat de vos traitements avant de remplacer la DataFrame*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpvoUoJWuyWS"
      },
      "source": [
        "**Question 10**\n",
        "\n",
        "Charger le fichier `cereal.csv` dans une DataFrame Spark SQL nommée `sdf1` (une description des données peut être trouvée [ici](https://www.kaggle.com/datasets/crawford/80-cereals/)).\n",
        "\n",
        "Vérifier que vous récupérer bien les en-têtes de colonne. Dans le cas contraire, adapter l'appel utilisé pour la lecture des données du fichier.\n",
        "\n",
        "Afficher le nombre de lignes contenus dans cette DataFrame, son nombre de partitions (en passant par le RDD sous-jacent) et ses 50 premières lignes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0L1qqO9FrBpr",
        "outputId": "d0043309-227b-4af9-ef93-685f5ae0986c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VW__0W1Yh7at"
      },
      "source": [
        "**Question 11**\n",
        "\n",
        "Afficher le schéma de la DataFrame avec la méthode `printSchema` et vérifier que vous obtenez les bons types. Dans le cas contraire, adapter l'appel utilisé pour la lecture des données du fichier afin d'inférer automatiquement le schéma.\n",
        "\n",
        "Afficher également l'attribut `schema` de la DataFrame avec `print()`. De quel type est cet objet ? Quel type d'objets contient-il ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwVhsN48rxLL",
        "outputId": "79eacca6-4581-42cf-b92c-32961e848281"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9RGUTLkjOuA"
      },
      "source": [
        "**Question 12**\n",
        "\n",
        "En une seule instruction, supprimer la colonne intitulée `\"shelf\"` puis renommer l'ensemble des colonnes restant (en utilisant une des méthodes `toDF` ou `withColumnRenamed`) avec, dans l'ordre, les intitulés suivants :\n",
        "\n",
        "```python\n",
        "\"Nom\", \"Fabricant\",\"Type\", \"Calories\",\"Protéines\", \"Graisse\",\"Sodium\",\"Fibres\",\\\n",
        "\"Glucides\",\"Sucre\",\"Potassium\", \"Vitamines\", \"Poids\",\"Volume\",\"Evaluation\"\n",
        "```\n",
        "\n",
        "Afficher la nouvelle DataFrame obtenue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD0bmbJUjhpP",
        "outputId": "41952a8c-0caf-4a2d-ed19-34547194def7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vK6Sf_ApjDh"
      },
      "source": [
        "**Question 13**\n",
        "\n",
        "En utilisant les dictionnaires `dic_fabricant` et `dic_type` ci-dessous, remplacer à l'aide de la méthode `replace` les valeurs des colonnes `Fabricant` et `Type` par les nouvelles valeurs associées.\n",
        "\n",
        "Afficher la nouvelle DataFrame obtenue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ-zDArBpVh0",
        "outputId": "6956a1cc-2ef4-49e0-c404-f00401b6930a"
      },
      "outputs": [],
      "source": [
        "dic_fabricant = {\"A\":\"American Home Food Products\",\n",
        "    \"G\" : \"General Mills\",\n",
        "    \"K\" : \"Kelloggs\",\n",
        "    \"N\" : \"Nabisco\",\n",
        "    \"P\" : \"Post\",\n",
        "    \"Q\" : \"Quaker Oats\",\n",
        "    \"R\" : \"Ralston Purina\"}\n",
        "\n",
        "dic_type = {\"C\" : \"froid\", \"H\" : \"chaud\"}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hpf2LPDKwKz6"
      },
      "source": [
        "**Question 14**\n",
        "\n",
        "En utilisant la méthode `withColumns`, convertir les poids donnés en *ounces* (onces) en grammes (1 once = 28,35 grammes) et les volumes donnés en *cups* (tasses) en litres (1 tasse = 0,25 litres)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHKPXANPxKHy",
        "outputId": "3b461a25-dd67-4dac-aa72-58f66c563caf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNQfecVF8ogt"
      },
      "source": [
        "### Re-partitionnement et écriture des nouvelles données\n",
        "\n",
        "**Question 15**\n",
        "\n",
        "A l'aide de la méthode `repartitionByRange` re-partitionner la DataFrame `sdf1` en 2 partitions en fonction du fabricant.\n",
        "\n",
        "Afficher le nombre de partitions de la nouvelles DataFrame `sdf1` et ses 50 premières lignes. Comparer à l'affichage obtenu à la question précdente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPJmDJHe6W9o",
        "outputId": "498839fe-b811-4d12-8991-bd992b48a953"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M53r1ndA9JLT"
      },
      "source": [
        "**Question 16**\n",
        "\n",
        "Ecrire la nouvelle Dataframe re-partitionnée `sdf1` dans un sous-répertoire `cereal_french` du répertoire `tp_pyspark` du HDFS au format `csv` avec les en-têtes. Observer le résutat obtenu.\n",
        "\n",
        "D'après le contenu de chaque fichier obtenu, comment ont été faites les partitions de `sdf1` ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3I0oJke6_30"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_n08rGx-iR_"
      },
      "source": [
        "### Filtrage, tri, groupements et agrégation.\n",
        "\n",
        "**Question 17**\n",
        "\n",
        "Afficher les lignes correspondant aux céréales avec des glucides strictement inférieurs à 10 grammes (on excluera également les valeurs négatives de glucides qui correspondent à des informations non renseignées). Ordonner les résultats suivant les glucides."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bL4tpLUEymlo",
        "outputId": "ec6d9a8a-0c63-4717-d02f-c7eab396c328"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnpejEt5BWtA"
      },
      "source": [
        "**Question 18**\n",
        "\n",
        "Afficher le nombre de céréales par type (chaud/froid)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7aZ0PqIyTPV",
        "outputId": "06a3e23e-70ae-45bd-c65e-8c3b485b3c17"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr5akeClBr_J"
      },
      "source": [
        "**Question 19**\n",
        "\n",
        "Créer une nouvelle DataFrame `sdf2` contenant les moyennes des grandeurs numériques par fabricant et renommer les colonnes de cette DataFrame avec dans l'ordre :\n",
        "```\n",
        "\"Fabricant\",\"Calories\",\"Protéines\",\"Graisse\",\"Sodium\",\"Fibres\",\n",
        "\"Glucides\",\"Sucre\",\"Potassium\", \"Vitamines\", \"Poids\",\"Volume\",\"Evaluation\"\n",
        "```\n",
        "\n",
        "Afficher le nombre de partitions de cette DataFrame `sdf2` et son contenu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiy-g7GByj_T",
        "outputId": "704dd92c-0b15-4fe0-c4cd-7310520ae866"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDCyDBpzCt_v"
      },
      "source": [
        "**Question 20**\n",
        "\n",
        "En utilisant la méthode `coalesce` rassembler la DataFrame `sdf2` en une seule partition puis l'écrire dans un répertoire `./fabricant_valeurs_moyennes` au format `csv` (avec les en-têtes). Observer le résutat obtenu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lc64sP3K1fmQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0mHv9KcEJgs"
      },
      "source": [
        "**Question 21**\n",
        "\n",
        "Exécuter la cellule de code ci-dessous pour arrêter votre `SparkSession` (on suppose que votre objet `SparkSession` s'appelle `spark`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Brkf3nRIESUk"
      },
      "outputs": [],
      "source": [
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
