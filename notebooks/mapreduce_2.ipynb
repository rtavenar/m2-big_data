{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MapReduce 2/2\n",
    "\n",
    "Dans cette séance vous allez écrire une fonction générique permettant d'enchainer le flux de traitements du modèle MapReduce à partir de `mapper ` et `reducer` à fournir pour un problème donné. Vous utiliserez ensuite cette fonction pour implémenter le calcul des PageRank d'un graphe dans le cadre MapReduce. \n",
    "\n",
    "## Exercice #3 : fonction générique Map+Reduce\n",
    "\n",
    "Le but de l'exercice est d'écrire une fonction `map_reduce()` permettant d'implémenter les étapes du modèle MapReduce de façon générique, en respectant les formats de données d'entrée et de sortie des différentes étapes (listes de tuples `(clé, valeur)`, voir le schéma du flux donné en cours).\n",
    "\n",
    "La fonction prendra en entrée une liste de tuples `(clé d'entrée, valeur d'entrée)` correspondant aux données à traiter (paramètre `data`), une fonction définissant la partie Map (paramètre `mapper` ), et une fonction définissant la partie Reduce (paramètre `reducer`). Elle renverra une liste des tuples `(clé de sortie, valeur de sortie)` issus de l'étape Reduce finale.\n",
    "\n",
    "Les fonctions définissant les paramètres `mapper` et `reducer` devront être adaptées au problème considéré et respecter les contraintes suivantes :\n",
    " - une fonction de type `mapper` prendra en paramètre un tuple `(clé d'entrée, valeur d'entrée)` et devra traiter cette entrée pour fournir une liste de tuples `(clé intermédiaire, valeur intermédiaire)`. *Remarque : à cette étape les clés intermédiaires ne sont pas nécessairement uniques et il peut même y avoir une seule clé intermédiaire pour toutes les valeurs intermédiaires (c'est le cas lorsque toutes les valeurs intermédiaires devront être agrégées en une valeur unique par le processus Reduce).*\n",
    " - une fonction de type `reducer` prendra en entrée un tuple `(clé intermédiaire, [liste de valeurs intermédiaires])` et devra traiter cette entrée pour fournir une liste de tuples `(clé de sortie, valeur de sortie)` répondant au problème considéré (cette liste de sortie peut éventuellement contenir un seul tuple `(clé de sortie, valeur de sortie)` pour un processus `reduce` donné).\n",
    "\n",
    "Entre les étapes Map et Reduce, une fonction `partitioner()` (identique à tous les problèmes) sera chargée de rassembler les valeurs intermédiaires par clé intermédiaire : elle prendra en entré une liste des listes de tuples `(clé intermédiaire, valeur intermédiaire)` issues des processus Map et fournira en sortie une liste de tuples `(clé intermédiaire, [liste de valeurs intermédiaires])` qui serviront d'entrée aux processus Reduce.\n",
    "\n",
    "Enfin, à l'issue des processus Reduce, les différentes listes de tuples `(clé de sortie, valeur de sortie)` seront rassemblées en une liste unique de tuples  `(clé de sortie, valeur de sortie)` qui sera retournée par la fonction `map_reduce()`.\n",
    "\n",
    "  \n",
    "**Question 3.1**\n",
    "\n",
    "Implémenter les fonctions `map_reduce()` et `partitioner()` en respectant les étapes et contraintes énoncées ci-dessus. A une étape donnée, les traitements indépendants seront lancés grâce à la fonction `map()` de Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2**\n",
    "\n",
    "Refaire l'exercice de la similarité cosinus en utilisant maintenant la fonction `map_reduce()` générique, en définissant les fonctions `mapper` et `reducer` appropriées. On commencera par réfléchie au paires `(clé, valeur)` à adopter à chaque étape des traitements.\n",
    "\n",
    "On rappelle qu'il y a trois traitements MapReduce distincts et indépendants pour le calcul de la similarité cosinus : deux pour le calcul des normes des deux vecteurs d'entrée, et un troisième pour le calcul du produit scalaire des deux vecteurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from functools import reduce\n",
    "from operator import add\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vecteur1 = list(range(1,10))\n",
    "vecteur2 = list(range(9,0,-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3**\n",
    "\n",
    "Refaire l'exercice du wordcount en utilisant maintenant la fonction `map_reduce()` générique et en définissant les fonctions `mapper` et `reducer` appropriées. On commencera par définir clairement quelles sont les clés et les valeurs à chaque étape du traitement : en entrée du `mapper`, en sortie du `mapper` (entrée du `partionner`), en sortie du `partionner` (entrée du `reducer`), et en sortie du `reducer`.\n",
    "\n",
    "*Indication : la fonction `mapper` pourra fournir ici une liste de tuples `(clé intermédiaire, valeur intermédiaire)` avec comme clés intermédiaires ***tous*** les mots du fichier traité, et comme valeur intermédiaire associée à chaque mot la valeur `1` comme indicateur de présence du mot (il n'y a donc pas dans ce cas de combinaison des occurences au niveau du `mapper`, elle se fera globalement au niveau du `partitioner`).*\n",
    "\n",
    "*Exemple de liste retournée : `[('modi', 1), ('ut', 1), ('amet', 1), ... ]`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise(text):\n",
    "    return text.lower().replace(\".\", \" \").split()\n",
    "\n",
    "data_in = [f\"data/wordcount/sample{i}.txt\" for i in range(3)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice #4 : PageRank en MapReduce\n",
    "\n",
    "Le but de l'exercice est d'implémenter le calcul du PageRank dans le cadre du modèle de programmation MapReduce. Le cadre réparti et distribué offert par MapReduce est particulièrement utile dans ce contexte car il n'est pas rare que la taille du graphe analysé soit gigantesque et que par conséquent celui-ci ne puisse tenir en totalité en mémoire sur une machine unique. C'est le cas par exemple du graphe représentant le web ou un réseau social tel que Facebook. \n",
    "\n",
    "Dans ce cas des \"morceaux\" du graphe sont répartis sur plusieurs machines et les traitements relatifs à un sous-graphes sont localisés sur la machine qui le contient. Il est donc impossible pour un noeud donné de connaitre l'ensemble de ses prédécesseurs car cela suppose d'explorer le graphe dans sa totalité. Par contre il est souvent assez simple d'obtenir les successeurs d'un noeud : dans le cadre du web par exemple, il s'agit des liens contenus dans la page correspondant au noeud. Un noeud et la liste de ses successeurs sont donc enregistrés au même endroit.\n",
    "\n",
    "La formule de base pour le calcul du PageRank d'un noeud $n$ d'un graphe vous est rappelée ci-dessous :\n",
    "$$r_n = \\frac{1 - \\alpha}{N} + \\alpha \\sum_{p \\rightarrow n} \\frac{r_p}{d_p}$$\n",
    "\n",
    "où $N$ est le nombre de noeuds dans le graphe, $p \\rightarrow n$ désigne l'ensemble des prédécesseurs de $n$, $r_p$ est le PageRank du prédécesseur $p$, $d_p$ est le degré sortant de $p$ et $\\alpha$ est le \"damping factor\" (valeurs typiques : 0.8 à 0.9).\n",
    "\n",
    "L'ensemble des PageRank d'un graphe est estimé de façon itérative par l'algorithme *power iteration*. L'implémentation utilisant la formule de base ci-dessus vous est donnée dans la fonction `pagerank()` ci-dessous qui prend en premier paramètre un graphe Networkx. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank(g, alpha=0.9, max_iter=100):  # est le graphe (networkx) analysé\n",
    "    N = g.order()\n",
    "    R = {node:1/N for node in g} # initialisation des pagerank\n",
    "    \n",
    "    for i in range(max_iter): # boucle d'itérations de l'algorithme power iteration\n",
    "        # print(f'iteration : {i}')\n",
    "        R_new={}\n",
    "        for node in g:  # boucle sur les noeuds\n",
    "            R_new[node] = 0\n",
    "            for pred in g.predecessors(node): # boucle sur les prédécesseurs du noeud\n",
    "                R_new[node] += R[pred]/g.out_degree(pred)\n",
    "            R_new[node] = alpha*R_new[node]+(1-alpha)/N    # utilisation du damping factor alpha\n",
    "        R = R_new  # mise à jour des pagerank\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La formule de base et l'implémentation qui vous sont données ci-dessus font directement intervenir les prédécesseurs des noeuds. Dans le cadre MapReduce avec un graphe répartis, il va donc falloir remanier l'algorithme pour pouvoir distribuer les calculs en faisant intervenir les successeurs des noeuds et non les prédécesseurs.\n",
    "\n",
    "Dans un premier temps vous aller visualiser le graphe étudié pour cet exercice et calculer ses Pagerank en utilisant l'implémentation de base afin d'avoir un résultat de référence. Bien entendu, pour pouvoir exécuter les programmes sur votre machine, le graphe utilisé est ici volaontairement de taille réduite.\n",
    "\n",
    "### Travail préliminaire : visualisation du graphe et calcul des PageRank\n",
    "\n",
    "**Question 4.1**\n",
    "\n",
    "Le graphe vous est pour l'instant fourni en totalité dans le fichier `graph_web.txt` au format EdgeList (à placer dans un dossier `data/graphe/`). \n",
    "\n",
    "A l'aide du module NetworkX, charger et visualiser ce graphe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2**\n",
    "\n",
    "A l'aide de la fonction `pagerank()` fournie, calculer les PageRank des noeud de ce graphe et les afficher par ordre décroissant du PageRank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.3**\n",
    "\n",
    " Proposer une fonction `pagerank_succ()` avec les mêmes paramètres d'entrée que `pagerank()` et qui implémente l'algorihtme *power iteration* en utilisant uniquement l'information des successeurs des noeuds.\n",
    "\n",
    " Le principe ici est le suivant :\n",
    " - calculer pour chaque noeud $n$ la contribution qu'il apporte au PageRank de chacun de ses successeurs : $\\frac{r_n}{d_n}$ où $r_n$ est le PageRank de $n$ et $d_n$ est le degré sortant de $n$\n",
    " - rassembler et additionner toutes les contributions associées à un même noeud pour obtenir le terme de somme dans la formule de base, puis appliquer le damping factor. Cas particulier : un noeud qui n'est le successeur d'aucun autre (et qui n'a donc aucune contribution associée) se verra attribuer un PageRank de $\\frac{1 - \\alpha}{N}$.\n",
    " \n",
    " Tester cette fonction sur le même graphe et vérifier qu'elle donne des résultats cohérents avec ceux de la première fonction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implémentation du PageRank dans le cadre MapReduce\n",
    "\n",
    "Nous allons maintenant nous placer dans le cas où le graphe est réparti en plusieurs fichiers et où il ne peut pas être exploré dans sa totalité pour pouvoir trouver l'ensemble des prédécesseurs d'un noeud. Les différentes parties de ce graphe vous sont données dans les fichiers `graphe_web_0.txt` jusqu'à `graphe_web_5.txt`, sous forme de listes d'adjacence : chaque ligne donne la liste des successeurs d'un noeud du graphe, avec en première position le noeud considéré, suivi de ses successeurs, le tout séparé par des espaces. Un noeud n'apparait qu'une seule fois en première position dans l'ensemble des lignes rassemblées de tous les fichiers.\n",
    "\n",
    "Le but ici est d'écrire une fonction `mr_pagerank()` permettant de calculer le PageRank des noeuds dans le cadre MapReduce en utilisant la fonction générique `map_reduce()` écrite précédemmment. La fonction `mr_pagerank()` prendra en entrée la liste des fichiers contenant le graphe réparti, le paramètre `alpha` représentant le damping factor choisi (valeur par défaut de 0.9) et le paramètre `max_iter` représentant le nombre d'itérations pour la convergence du PageRank (valeur par défaut de 100).\n",
    "\n",
    "#### Analyse préliminaire\n",
    "\n",
    "**Question 4.4**\n",
    "\n",
    "Identifier les calculs indépendants sur des sous-patrties des données d'entrée qui pourront constituer la partie \"Map\" du traitement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[*VOTRE REPONSE ICI*]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.5**\n",
    "\n",
    "Identifier les calculs d'agrégation qui constitueront la partie \"Reduce\" du traitement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[*VOTRE REPONSE ICI*]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.6**\n",
    "\n",
    "Identifier les paires `(clé , valeur)` à mettre en oeuvre à chaque niveau du flux de traitement MapReduce : en entrée et en sortie des `mapper`, en entrée et en sortie du `partitioner`, en entrée et en sortie du ou des `reducer`.\n",
    "\n",
    "*Indication : veiller à ce qu'une paire `(clé, valeur)` contienne tous les éléments nécessaires au traitement suivant et adapter la `clé` et/ou la `valeur` en conséquence (une `clé` ou une `valeur` peut elle-même être un tuple contenant plusieurs éléments)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[*VOTRE REPONSE ICI*]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mise en oeuvre du code\n",
    "\n",
    "*Pour l'ensemble des questions suivantes, vous écrirez votre code dans la cellule qui suit les questions.* \n",
    "\n",
    "**Question 4.7**\n",
    "\n",
    "Ecrire une fonction `get_nodes_and_successors()` qui prend en entrée un nom de fichier contenant une sous-partie du graphe et qui permet de récupérer un ensemble de noeuds associés chacun à la liste de ses successeurs. La fonction renverra une liste de tuples `(noeud, [liste des successeurs du noeud])`.\n",
    "\n",
    "**Question 4.8**\n",
    "\n",
    "Définir la fonction `mr_pagerank()` et y écrire une instruction qui permet de récupérer l'ensemble des noeuds du graphe associés à la liste de leurs successeurs en utilisant les fonctions `get_nodes_and_successors()` et `map()`.\n",
    "\n",
    "**Question 4.9**\n",
    "\n",
    "Ecrire la fonction `pr_mapper()` chargée d'effectuer les traitements de la partie Map.\n",
    "\n",
    "**Question 4.10**\n",
    "\n",
    "Ecrire la fonction `pr_reducer()` chargée d'effectuer les traitements de la partie Reduce.\n",
    "\n",
    "**Question 4.11**\n",
    "\n",
    "Compléter la fonction `mr_pagerank()`:\n",
    "- calculer le nombre $N$ de noeuds dans le graphe\n",
    "- initialiser les données d'entrée avec les PageRank initiaux de l'algorithme *power iteration*\n",
    "- mettre en place la boucle d'itérations de l'algorithme *power iteration* qui utilisera la fonction `map_reduce()` pour calculer les valeurs mises à jour des PageRank.\n",
    "- la fonction devra retourner une liste de tuples `(noeud, pagerank du noeud)` \n",
    "\n",
    "*Indication : il n'est pas possible de passer dynamiquement des valeurs au `mapper` et au `reducer` de la fonction `map_reduce()`, comme le paramètre `alpha` choisi par l'utilisateur ou le nombre $N$ de noeuds déterminé seulement après avoir parcouru les fichiers d'entrée. Ces paramètres sont pourtant nécessaires au calcul des PageRank. On pourra cependant utiliser une redéfinition dynamique de fonction comme dans l'exemple suivant :*\n",
    "\n",
    "`my_pr_mappper = lambda x : pr_mapper(x, valeur1, valeur2)`\n",
    "\n",
    "*où `valeur1` et `valeur2` sont des valeurs attribuées dynamiquement à des paramètres d'entrée de la fonction `pr_mapper`. C'est ensuite la référence `my_pr_mapper` qui sera passé en paramètre de la fonction `map_reduce()` (pour le paramètre `mapper`).*\n",
    "\n",
    "**Question 4.12**\n",
    "\n",
    "Tester la fonction `mr_pagerank()` en affichant les résultats par ordre décroissant des PageRank et comparer aux résultats obtenus avec les autres fonctions.\n",
    "\n",
    "Le PageRank du noeud `PAGE_61` (correspondant à la dernière ligne du fichier `graph_web_5.txt`) apparait-il dans les résultats de votre fonction `mr_pagerank()` ?\n",
    "\n",
    "Si ce n'est pas le cas, identifier le problème et y remédier.\n",
    "\n",
    "*Indication : on pourra remarquer que*\n",
    "\n",
    "$$r_n = \\frac{1 - \\alpha}{N} + \\alpha \\sum_{p \\rightarrow n} \\frac{r_p}{d_p} =  \\alpha . \\left( \\sum_{p \\rightarrow n} \\frac{r_p}{d_p} +\\frac{1 - \\alpha}{\\alpha.N} \\right)$$\n",
    "\n",
    "*On pourra donc ajouter par défaut une contribution $\\frac{1 - \\alpha}{\\alpha.N}$ à tous les noeuds du graphe (y compris ceux sans prédécesseur) et faire ensuite une somme globale de toutes les contributions (à multiplier par $\\alpha$ pour obtenir le PageRank final).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "data_mr_pr = [f\"data/graphe/graph_web_{i}.txt\" for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test de la fonction mr_pagerank()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
