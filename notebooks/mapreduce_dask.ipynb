{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitements parallèles et MapReduce avec `dask`\n",
    "\n",
    "Dans cette séance vous allez utiliser le module `dask` pour effectuer des traitements parallèles dans le cadre du modèle MapReduce.\n",
    "\n",
    "## Exercice #1 : fonction de type Map avec `dask`\n",
    "\n",
    "Le module `dask` ne fournit pas de fonction de type `map` utilisable directement sur les structures de données itérables de base de Python (le module fournit cependant ce type de fonction pour des types de données propres au module tel que les *Dask Bags* ou les *Dask Dataframes*).\n",
    "\n",
    "Le but de l'exercice est de créer et tester une fonction `dask_map()` qui soit interchangeable avec la fonction `map()` de Python mais qui permette d'avoir une parallélisation des calculs. \n",
    "\n",
    "*Remarque : pour mettre en évidence l'avantage des calculs parallèles, pour cet exercice certaines fonction de traitement sont rendues volontairement lentes.*\n",
    "\n",
    "**Question 1.1**\n",
    "\n",
    "Proposer une fonction `dask_map()` qui, dans son utilisation la plus simple, prend en premier argument le nom d'une fonction, en second argument un itérable et qui applique la fonction à chaque élément de l'itérable. La fonction renverra une liste de résultats, similaire à l'itérateur retourné par la fonction `map()`.\n",
    "\n",
    "Les calculs indépendants devront se faire en parallèle grâce aux fonctionnalités du module `dask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "\n",
    "# code de votre fonction dask_map()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2**\n",
    "\n",
    "Tester votre fonction sur le calcul \"lent\" de la norme d'un vecteur en utilisant la fonction `carre_slow()` fournie ci-dessous. Afficher les temps de calcul avec `%%time` et comparer avec l'utilisation de la fonction `map()` (en utilisant également `carre_slow()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from math import sqrt\n",
    "from operator import add\n",
    "from functools import reduce\n",
    "\n",
    "def freeze(t):\n",
    "    st = time.time()\n",
    "    et = st\n",
    "    while et - st < t:\n",
    "        et = time.time()\n",
    "\n",
    "def carre_slow(x1):\n",
    "    freeze(1)\n",
    "    return x1**2\n",
    "\n",
    "vecteur1 = [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# code pour tester avec dask_map()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# code pour tester avec map()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3** \n",
    "\n",
    "Modifier la fonction `dask_map()` pour pouvoir également gérer le cas ou l'on fournit une liste d'itérables séparés par des virgules (en nombre quelconque) après le nom de la fonction (la fonction doit alors avoir plusieurs arguments d'entrée). Dans ce cas, la fonction fournie est appliquée à chaque groupe d'éléments pris position par position dans les différents itérables, comme le fait la fonction `map()`.\n",
    "\n",
    "*Indication 1 : on rappelle que l'on peut récupérer tout ou partie des arguments passés à une fonction sous forme d'un tuple en utilisant l'opérateur \"splat\" (ou \"étoile\" : `*` ) dans la définition de la fonction.*\n",
    "\n",
    "*Tester le code ci-dessous :*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ma_fonction(x, *args):\n",
    "    print(f\"x={x}\")\n",
    "    print(f\"args={args}\")\n",
    "\n",
    "ma_fonction(1, [2,3], (4,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Indication 2 : d'autre part, on rappelle que l'on peut décompacter (\"unpack\") les éléments d'un itérable en utilisant le même opérateur `*` devant le nom de l'itérable. Cela permet notamment de fournir les éléments de l'itérable comme arguments individuels d'une fonction lors de son appel.*\n",
    "\n",
    "*Tester le code ci-dessous :*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ma_fonction2(x, ma_liste, mon_tuple):\n",
    "    print(f\"x={x}\")\n",
    "    print(f\"ma_liste={ma_liste}\")\n",
    "    print(f\"mon_tuple={mon_tuple}\")\n",
    "\n",
    "param = [1, [2,3], (4,5)]\n",
    "\n",
    "ma_fonction2(*param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cellule pour le code de votre nouvelle fonction dask_map()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4**\n",
    "\n",
    "Tester cette nouvelle fonction `dask_map()` sur le calcul \"lent\" du produit scalaire de deux vecteurs en utilisant la fonction `produit_slow()` fournie ci-dessous. Afficher les temps de calcul avec `%%time` et comparer avec l'utilisation de la fonction `map()` (en utilisant également `produit_slow()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produit_slow(x,y):\n",
    "    freeze(1)\n",
    "    return x*y\n",
    "\n",
    "vecteur2 = [4, 3, 2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# code pour tester avec dask_map()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# code pour tester avec map()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5**\n",
    "\n",
    "Ecrire une fonction `sim_cos_dask_map()` qui calcule et renvoie la similarité cosinus entre deux vecteurs en utilisant des processus MapReduce impliquant les fonctions `dask_map()`, `reduce()`, `carre_slow()`et `produit_slow()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code de votre fonction sim_cos_dask_map()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.6**\n",
    "\n",
    "Tester cette fonction `sim_cos_dask_map()` sur les vecteurs `vecteur1` et `vecteur2` en affichant les temps de calcul avec `%%time` et comparer aux temps de calcul obtenus avec la fonction `sim_cos_map()` fournie ci-dessous qui utilise la fonction classique `map()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_cos_map(v1, v2):\n",
    "    norm1 = reduce(add, map(carre_slow,v1))\n",
    "    norm2 = reduce(add, map(carre_slow,v2))\n",
    "    prod = reduce(add, map(produit_slow, v1, v2))\n",
    "\n",
    "    return prod/sqrt(norm1*norm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# code pour le test de sim_cos_dask_map()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# code pour le test de sim_cos_dask_map()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.7**\n",
    "\n",
    "Expliquez pourquoi l'implémentation du calcul de la similarité cosinus proposée dans `sim_cos_dask_map()` n'est pas optimale vis-à-vis des fonctionnalités de parallélisation et d'ordonnacement des calculs de  `dask`.\n",
    "\n",
    "Proposer une nouvelle implémentation de `dask_map()` (à renommer) et de `sim_cos_dask_map()` (à renommer également) qui soient optimales. Tester et comparer les temps de calcul des deux implémentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code de vos nouvelles fonctions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# code pour tester vos nouvelles fonctions et visualiser les temps d'exécution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice #2 : wordcount en MapReduce parallélisé\n",
    "\n",
    "Reprendre l'exercice du wordcount qui utilise la fonction générique `map_reduce()` mais cete fois-ci en parallélisant les calculs des étapes de type Map grâce à la fonction `dask_map()` écrite précédemment. On ajoutera les instructions nécessaires pour ralentir artificiellement les fonctions impliquées dans les étapes Map (par exemple : 2 secondes d'attente pour le `mapper_word()` et 0.5 seconde d'attente pour le `reducer_word()`). Utiliser les fichiers d'entrée `sample0.txt`, `sample1.txt` et `sample2.txt` générés lors de l'exercice précédent sur wordcount.\n",
    "\n",
    "Pour pouvoir facilement comparer le gain de temps apporté par la parallélisation des calculs, on pourra ajouter à la fonction `map_reduce()` un paramètre booléen `parallelise` (valeur par défaut à `False`) permettant de basculer entre l'utilisation de la fonction `map()` classique (i.e. sans parallélisation) et de la fonction `dask_map()` parallélisant les cacluls.\n",
    "\n",
    "Les codes de la fonction `map_reduce()` et de l'exercice de base du wordcount utilisant cette fonction vous sont fournis ci-dessous (codes à modifier pour l'exercice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code de la fonction générique map_reduce()\n",
    "\n",
    "def partitioner(list_of_list):\n",
    "    dic_partition = {}\n",
    "    for l in list_of_list :\n",
    "        for cle, val in l :\n",
    "            dic_partition[cle] = [val] if cle not in dic_partition else dic_partition[cle]+[val]\n",
    "    return list(dic_partition.items())\n",
    "\n",
    "def map_reduce(data, mapper, reducer):\n",
    "    list_of_list_inter = map(mapper, data)\n",
    "    list_inter = partitioner(list_of_list_inter)\n",
    "    list_red = map(reducer, list_inter)\n",
    "\n",
    "    return [(cle, val) for l in list_red for (cle, val) in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code du wordcount en MapReduce\n",
    "def tokenise(text):\n",
    "    return text.lower().replace(\".\", \"\").split()\n",
    "\n",
    "import lorem\n",
    "\n",
    "data_wordcount = [f\"data/wordcount/sample{i}.txt\" for i in range(3)]\n",
    "\n",
    "def mapper_words(cle_val):\n",
    "    filename = cle_val[1]\n",
    "    with open(filename, 'rt', encoding='utf-8') as ifile:\n",
    "        content = ifile.read()\n",
    "    return [(w,1) for w in tokenise(content)]\n",
    "\n",
    "def reducer_words(cle_val):\n",
    "    return [(cle_val[0], len(cle_val[1]))]\n",
    "\n",
    "data_mr_wordcount = list(enumerate(data_wordcount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# code pour tester votre implémentation modifiée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice #3 : PageRank en MapReduce parallélisé\n",
    "\n",
    "Reprendre l'exercice du PageRank en utilisant la fonction générique `map_reduce()` modifiée lors de l'exercice 2 ci-dessus. Ajouter un paramètre `parallelise` à la fonction `mr_pagerank()` qui sera transmis dircetement à la fonction `map_reduce()` pour pouvoir basculer d'un traitement sans parallélisation (par défaut) à un traitement avec parallélisation.\n",
    "\n",
    "On ajoutera les instructions nécessaires pour ralentir artificiellement les fonctions impliquées dans les étapes Map (par exemple : 0.1 secondes d'attente pour le `pr_mapper` et 0.1 seconde d'attente pour le `pr_reducer`). Utiliser les fichier `graph_web0.txt` à `graph_web5.txt` du graphe réparti fournis lors de l'exercice précédent sur PageRank..\n",
    "\n",
    "Sachant que le graphe complet utilisé comporte 61 noeuds et en se limitant à 10 itérations de l'algorithme *power iteration*, prévoir un ordre de grandeur du temps nécessaire au calcul des PageRank dans le cas non parallélisé.\n",
    "Tester et comparer les temps de traitement des deux implémentation en utilisant `%%time`.\n",
    "\n",
    "*[Votre réponse ici]()*\n",
    "\n",
    "Le code de l'exercie précédent du PageRank en MapReduce vous est fourni ci-dessous (à modifier pour l'exercice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes_and_successors(filename):\n",
    "    out_list = []\n",
    "    with open(filename, 'rt', encoding=\"utf-8\") as i_file:\n",
    "        for line in i_file.readlines():\n",
    "            line = line.strip().split()\n",
    "            out_list.append((line[0], line[1:]))\n",
    "    return out_list\n",
    "\n",
    "def pr_mapper(my_tuple, alpha, N):\n",
    "    (node, successors), pr = my_tuple\n",
    "    nbs = len(successors)\n",
    "    outlist = []\n",
    "    outlist.append((node, (1 - alpha)/(alpha*N))) # pour traiter le cas des noeuds sans prédécesseur (question 4.12)\n",
    "    contrib = pr/nbs\n",
    "    for s in successors:\n",
    "        outlist.append((s,contrib))\n",
    "    return outlist\n",
    "\n",
    "def pr_reducer(tuple, alpha):\n",
    "    node, lst_pr = tuple\n",
    "    pr = alpha*reduce(add, lst_pr)  # formule qui prend en compte le traitement spécial des noeuds sans prédécesseur (question 4.12)\n",
    "    return [(node, pr)]\n",
    "\n",
    "\n",
    "def mr_pagerank(data_mr, alpha=0.9, max_iter=100):\n",
    "    nodes_and_successors  = {x[0]:x[1] for l in map(get_nodes_and_successors, data_mr) for x in l}\n",
    "    N = len(nodes_and_successors)\n",
    "    R = [((node, successors), 1/N) for node,successors in nodes_and_successors.items()]\n",
    "    my_pr_mapper = lambda x : pr_mapper(x, alpha, N)\n",
    "    my_pr_reducer = lambda x : pr_reducer(x, alpha)\n",
    "    for i in range(max_iter):\n",
    "        print(f'iteration {i}')\n",
    "        mr_res = map_reduce(R, my_pr_mapper, my_pr_reducer)\n",
    "        R = [((node, nodes_and_successors[node]), pr) for node, pr in mr_res]\n",
    "\n",
    "    return mr_res\n",
    "\n",
    "data_mr = [f\"data/graphe/graph_web_{i}.txt\" for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# code pour tester votre nouvelle implémentation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
